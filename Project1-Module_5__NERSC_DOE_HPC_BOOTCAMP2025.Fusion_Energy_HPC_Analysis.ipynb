{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c98156b1",
   "metadata": {},
   "source": [
    "# Module 5: HPC Workload and Energy Analysis in Fusion Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d017052b",
   "metadata": {},
   "source": [
    "\n",
    "## üéØ Learning Outcomes\n",
    "\n",
    "By the end of this project, you will be able to:\n",
    "\n",
    "- Investigate HPC resource utilization patterns in fusion energy research using Python.\n",
    "- Interpret performance data and scaling behaviors across fusion workloads at NERSC.\n",
    "- Collaborate on proposing optimizations and insights to improve the efficiency of fusion simulations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd0b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Synthetic dataset mimicking HPC fusion workloads\n",
    "df = pd.DataFrame({\n",
    "    'JobID': range(1, 11),\n",
    "    'Project': ['DIII-D', 'NSTX-U', 'NIF', 'DIII-D', 'NIF', 'NSTX-U', 'DIII-D', 'NIF', 'NSTX-U', 'DIII-D'],\n",
    "    'Facility': ['NERSC', 'Summit', 'NERSC', 'Frontier', 'Frontier', 'Summit', 'NERSC', 'Summit', 'Frontier', 'NERSC'],\n",
    "    'Cores': [512, 1024, 2048, 1024, 4096, 2048, 512, 1024, 2048, 1024],\n",
    "    'RuntimeMinutes': [120, 180, 300, 90, 400, 150, 110, 190, 210, 130],\n",
    "    'JobType': ['Simulation', 'ML', 'Post-processing', 'Simulation', 'ML', 'Simulation', 'Simulation', 'ML', 'Post-processing', 'ML'],\n",
    "    'Energy_kWh': [150, 320, 600, 130, 950, 500, 145, 315, 525, 330]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09f43cb",
   "metadata": {},
   "source": [
    "## üåü Introduction\n",
    "\n",
    "\n",
    "Welcome to the **Fusion Energy & High-Performance Computing (HPC)** module ‚Äî an exciting journey into the technologies powering the **future of clean energy** and scientific discovery! \n",
    "\n",
    "Fusion energy ‚Äî the process that powers the Sun ‚Äî promises a virtually limitless and sustainable source of energy for our planet. Researchers across the globe, including at leading **U.S. Department of Energy (DOE)** laboratories, are working to bring this stellar energy source to Earth. \n",
    "\n",
    "However, harnessing fusion isn't easy. It involves **extreme conditions**, **complex physics**, and **massive data volumes**. That's where **High-Performance Computing (HPC)** comes in. DOE labs like [LLNL](https://www.llnl.gov/), [ORNL](https://www.ornl.gov/), and [PPPL](https://www.pppl.gov/) rely on some of the **fastest supercomputers in the world** to simulate plasma behavior, optimize reactor designs, and process experimental data.\n",
    "\n",
    "---\n",
    "\n",
    "### üåê Why Fusion + HPC?\n",
    "\n",
    "- üî¨ **Modeling extreme plasma physics** ‚Äî where temperatures exceed millions of degrees.\n",
    "- üß† **Training AI/ML models** to predict reactor behavior.\n",
    "- ‚öôÔ∏è **Designing and testing reactor materials** under intense conditions.\n",
    "- üìà **Analyzing massive datasets** from experiments and simulations.\n",
    "\n",
    "---\n",
    "\n",
    "### üñºÔ∏è Visual: Fusion & Supercomputing\n",
    "\n",
    "![Fusion Energy](https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/NIF_target_chamber.jpg/800px-NIF_target_chamber.jpg)\n",
    "*Image: Target chamber of the National Ignition Facility (NIF), a fusion experiment at LLNL.*  \n",
    "*Source: Wikimedia Commons*\n",
    "\n",
    "---\n",
    "\n",
    "By the end of this module, you'll gain insight into how **HPC accelerates breakthroughs** in fusion research ‚Äî and how your future work can contribute to this critical mission.\n",
    "\n",
    "Let‚Äôs ignite the stars here on Earth ‚Äî together. üåüüåç\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ea518",
   "metadata": {},
   "source": [
    "## üí° Goals of this Module\n",
    "\n",
    "This 3-day project module is designed to help you explore how **fusion energy research** and **high-performance computing** intersect in real-world DOE applications.\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "üîπ **Explain** the fundamentals of fusion energy and how it differs from fission.  \n",
    "üîπ **Understand** why HPC systems are essential for modeling fusion reactions.  \n",
    "üîπ **Analyze** synthetic fusion workload data using Python and common scientific libraries.  \n",
    "üîπ **Visualize** patterns in computational demand across DOE fusion experiments.  \n",
    "üîπ **Present findings** in a short group report simulating a DOE project debrief.\n",
    "\n",
    "This project combines **scientific computing**, **data analysis**, and **real-world DOE mission contexts**, giving you a unique opportunity to contribute to one of the most important scientific challenges of our time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84639a50",
   "metadata": {},
   "source": [
    "## üñ•Ô∏è HPC Systems Used for Fusion Research\n",
    "\n",
    "To unlock the secrets of fusion, DOE researchers rely on some of the world‚Äôs most advanced supercomputers. These systems simulate plasma dynamics, materials stress, and energy confinement in complex fusion devices like **tokamaks** and **laser-based inertial confinement reactors**.\n",
    "\n",
    "Here are some notable HPC systems and how they contribute to fusion:\n",
    "\n",
    "### üî∑ NERSC ‚Äî Perlmutter (LBNL)\n",
    "- Used for plasma simulation, turbulence modeling, and data analysis.\n",
    "- Houses both CPU and GPU nodes, ideal for parallel workloads.\n",
    "\n",
    "### üî∑ Summit (ORNL)\n",
    "- Powered deep learning efforts in fusion forecasting and control.\n",
    "- Supported research into magnetic confinement and MHD (magnetohydrodynamic) stability.\n",
    "\n",
    "### üî∑ Frontier (ORNL)\n",
    "- World‚Äôs first exascale supercomputer (as of 2024).\n",
    "- Enables multi-scale modeling of fusion materials and magnetic fields.\n",
    "\n",
    "### üî∑ Cori (LBNL) *(Retired but historically important)*\n",
    "- Served fusion researchers developing scalable codes like **XGC** and **GTC**.\n",
    "\n",
    "---\n",
    "\n",
    "### üßë‚Äçüî¨ Why HPC is Essential for Fusion:\n",
    "- Fusion involves **nonlinear, multi-physics phenomena**.\n",
    "- Requires **high spatial and temporal resolution** to simulate plasma behavior.\n",
    "- Real-time data from experiments can produce **terabytes per run**.\n",
    "- HPC allows researchers to test **thousands of reactor configurations** virtually.\n",
    "\n",
    "---\n",
    "\n",
    "üìé *Further Reading:*\n",
    "- [Fusion Energy Sciences at DOE](https://science.osti.gov/fes)\n",
    "- [NERSC Science Highlights](https://www.nersc.gov/news-publications/science-highlights/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce138d08",
   "metadata": {},
   "source": [
    "\n",
    "## üá∫üá∏ National Strategy: The DOE Fusion Energy Vision\n",
    "\n",
    "The **U.S. Department of Energy (DOE)** has unveiled an ambitious roadmap for commercializing fusion energy, driven by the **Fusion Energy Strategy 2024** and the **Fusion Energy Sciences (FES) Building Bridges Vision**. These strategic blueprints are guiding the U.S. toward realizing commercially viable fusion systems within the next decade.\n",
    "\n",
    "Key pillars include:\n",
    "\n",
    "- **Commercial Deployment by the 2030s**: The DOE envisions rapid deployment of pilot plants through public-private partnerships.\n",
    "- **Closing Critical Technology Gaps**: From materials to reactor design, the strategy identifies shortfalls in confinement, tritium handling, and superconducting magnets.\n",
    "- **Integrated Research Infrastructure (IRI)**: By linking experimental facilities with HPC and real-time analysis tools like NERSC and ESnet, DOE aims to create an interconnected ecosystem.\n",
    "- **Workforce and Equity Goals**: Building a diverse, capable workforce through national training programs and inclusive partnerships is central to the plan.\n",
    "\n",
    "üìò [DOE Fusion Energy Sciences](https://www.energy.gov/science/fes/fusion-energy-sciences)  \n",
    "üìò [Fusion Energy Strategy 2024 PDF](https://science.osti.gov/-/media/fes/pdf/program-documents/FES-Fusion-Energy-Strategy-2024.pdf)  \n",
    "üìó White Paper: \"Building Bridges: FES Vision\" (2023)  \n",
    "üìö Sweeney, M. A., et al. (2023). *The U.S. Fusion Strategy: From Science to Commercialization*. Fusion Sci. & Tech.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721f2ec",
   "metadata": {},
   "source": [
    "\n",
    "## üî¨ DOE Facilities and Fusion Experiments\n",
    "\n",
    "The U.S. fusion ecosystem is anchored by world-class experimental facilities operating under the DOE Office of Science. These serve as both testbeds and data generators for fusion science and HPC modeling:\n",
    "\n",
    "- **DIII-D National Fusion Facility (GA, San Diego)**: The largest operational U.S. tokamak, contributing real-time profile diagnostics, disruption prediction data, and simulation validation.\n",
    "- **NSTX-U (Princeton Plasma Physics Lab)**: Focused on spherical tokamak physics, currently undergoing major upgrades after hardware failures.\n",
    "- **NIF (Lawrence Livermore National Laboratory)**: Inertial confinement facility where the first ignition-level fusion event occurred in Dec 2022, producing >3 MJ of energy.\n",
    "\n",
    "These experiments are deeply integrated with computational workflows. DIII-D, for example, sends real-time diagnostic data via **ESnet** to **NERSC‚Äôs Perlmutter**, where plasma reconstructions using MHD codes (e.g., EFIT++, TRANSP) guide experimental decisions within minutes.\n",
    "\n",
    "üìö References:\n",
    "- [DIII-D and HPC Integration](https://www.ga.com/diii-d-national-fusion-facility-nersc-and-esnet-collaboration-speeds-nuclear-fusion-research)\n",
    "- Hittinger, J. A., et al. (2023). *Accelerating Fusion Science with Integrated Infrastructure*. J. Comp. Plasma Physics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe7d95",
   "metadata": {},
   "source": [
    "\n",
    "## üî• Hands-On Activity: Fusion Facility Utilization Heatmap\n",
    "\n",
    "Using the synthetic dataset, let‚Äôs analyze HPC usage patterns across different DOE fusion experiments and facilities.\n",
    "\n",
    "We‚Äôll create a heatmap showing average runtime (in minutes) by facility and project type.\n",
    "\n",
    "This helps reveal which fusion centers are most HPC-intensive ‚Äî useful for resource planning and infrastructure scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a pivot table showing average runtime by Facility and Project\n",
    "heatmap_data = df.pivot_table(index='Project', columns='Facility', values='RuntimeMinutes', aggfunc='mean')\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"YlGnBu\", fmt=\".1f\")\n",
    "plt.title(\"Average Job Runtime by Facility and Project\")\n",
    "plt.ylabel(\"Fusion Project\")\n",
    "plt.xlabel(\"Facility\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5c749",
   "metadata": {},
   "source": [
    "\n",
    "## ü§ñ AI & Machine Learning in Fusion Research\n",
    "\n",
    "Artificial Intelligence (AI) and Machine Learning (ML) are emerging as powerful tools in fusion energy R&D. These techniques are being used to:\n",
    "\n",
    "- **Predict Disruptions**: ML models trained on DIII-D plasma shots predict disruptions with >90% accuracy (Kates-Harbeck et al., 2019).\n",
    "- **Guide Magnetic Control**: Reinforcement learning (RL) agents are being tested to control plasma shape in real time.\n",
    "- **Accelerate Simulation Workflows**: Surrogate models reduce compute time for gyrokinetic codes by orders of magnitude.\n",
    "\n",
    "### üß™ SciDAC Initiatives\n",
    "The DOE‚Äôs **Scientific Discovery through Advanced Computing (SciDAC)** program supports AI/ML infusion in MHD modeling, turbulence prediction, and materials degradation analysis.\n",
    "\n",
    "Discussion Prompt:\n",
    "> *How could AI be deployed in fusion reactors to make control decisions under uncertainty? What tradeoffs exist between accuracy, speed, and interpretability?*\n",
    "\n",
    "üß† [Learn more about SciDAC](https://www.scidac.gov/about.html)  \n",
    "üìö Kates-Harbeck, J., et al. (2019). *Predicting disruptive instabilities in fusion plasmas using deep learning*. Nature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edbce2",
   "metadata": {},
   "source": [
    "\n",
    "## üèõÔ∏è Policy, Startups & Commercialization\n",
    "\n",
    "Fusion is no longer a distant ambition‚Äîit's an active area of commercialization with strong federal backing.\n",
    "\n",
    "### üîπ DOE Support\n",
    "- **$1.4B in milestone-based grants** support U.S. fusion startups advancing toward pilot plants by the 2030s.\n",
    "- **Clean energy tax credit eligibility** (post-IRA) supports demo plant financing.\n",
    "- **TINEX** (Tokamak Innovation Network for Experimentation) is driving U.S. tokamak engineering innovation.\n",
    "\n",
    "### üîπ Leading Private Companies\n",
    "- **Commonwealth Fusion Systems (CFS)** ‚Äì MIT spinoff targeting net energy by 2026.\n",
    "- **Helion Energy** ‚Äì Field-reversed configuration with private PPAs.\n",
    "- **Zap Energy, TAE, General Fusion** ‚Äì Each pursuing alternate confinement approaches.\n",
    "\n",
    "### üîπ Workforce Initiatives\n",
    "- DOE and NSF fund workforce pipelines like the **FIRE Collaboratives** and **SCGSR Fellowship**.\n",
    "- Broader inclusion goals target MSIs and underrepresented groups.\n",
    "\n",
    "Discussion Prompt:\n",
    "> *Should the government continue subsidizing fusion if early commercial plants prove viable? What role does regulation play in ensuring safety and public trust?*\n",
    "\n",
    "üìó [CATF Analysis on U.S. Fusion Policy](https://www.catf.us/2025/06/fusion-energy-opportunities-federal-action-support-energy-innovation-commercialization/)\n",
    "üìä [DOE FOA 2025](https://science.osti.gov/grants/FOAs/-/media/grants/pdf/foas/2025/DE-FOA-0003516-000002.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06374d03",
   "metadata": {},
   "source": [
    "\n",
    "## üßë‚Äçüî¨ Capstone Option: DOE HPC Advisory Project\n",
    "\n",
    "This project gives you the opportunity to act as a strategic advisor to a national fusion initiative.\n",
    "\n",
    "### üìù Instructions:\n",
    "Choose one DOE-funded fusion project (e.g., DIII-D, NSTX-U, FIRE, Helion) and:\n",
    "\n",
    "1. **Research its experimental goals and reactor design.**\n",
    "2. **Analyze its synthetic or real HPC workload profile.**\n",
    "3. **Identify key performance challenges (latency, data volume, scalability).**\n",
    "4. **Recommend enhancements using DOE HPC resources (NERSC, Summit, Frontier) and ML techniques.**\n",
    "\n",
    "üìà Considerations:\n",
    "- How would AI-based diagnostics reduce HPC load?\n",
    "- Can real-time edge computing assist in-loop analysis?\n",
    "- Are Superfacility tools (ESnet + NERSC) sufficient?\n",
    "\n",
    "üìå Deliverables:\n",
    "- One infographic or 1-slide advisory report.\n",
    "- 2‚Äì3 paragraph memo to the DOE Office of Fusion Energy Sciences.\n",
    "\n",
    "üåê [Explore Projects and Collaborations](https://usfusionenergy.org)\n",
    "üìö Case Study: NERSC-DIII-D Workflow [GA Article](https://www.ga.com/diii-d-national-fusion-facility-nersc-and-esnet-collaboration-speeds-nuclear-fusion-research)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3002b1",
   "metadata": {},
   "source": [
    "\n",
    "## ü§ñ Mini ML Activity: Predicting Runtime from HPC Inputs\n",
    "\n",
    "Fusion workloads vary based on the number of cores used and project complexity. In this hands-on activity, we‚Äôll use a **linear regression model** to predict job runtime using core count and project type.\n",
    "\n",
    "This gives a basic example of how machine learning can support intelligent job scheduling or forecasting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae8c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepare the dataset\n",
    "X = df[['Cores', 'Project']]\n",
    "y = df['RuntimeMinutes']\n",
    "\n",
    "# One-hot encode project types\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "X_encoded = encoder.fit_transform(X[['Project']])\n",
    "X_full = pd.concat([pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out()), X['Cores'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811c315",
   "metadata": {},
   "source": [
    "## üìä Dataset Overview\n",
    "\n",
    "In this notebook, we‚Äôll use a **synthetic dataset** that mimics real-world fusion HPC workloads submitted to systems like NERSC‚Äôs **Perlmutter**. This data simulates what a workload trace might look like over time across multiple DOE experiments.\n",
    "\n",
    "### üìÅ Dataset Columns:\n",
    "- `JobID`: Unique identifier for each submitted job.\n",
    "- `Project`: Fusion project or facility (e.g., DIII-D, NSTX-U, NIF).\n",
    "- `SubmissionTime`: Timestamp of job submission.\n",
    "- `StartTime`, `EndTime`: Run time markers.\n",
    "- `NodesRequested`: Number of nodes requested.\n",
    "- `RuntimeMinutes`: Duration of the job.\n",
    "- `JobType`: Categorized workload (e.g., simulation, post-processing, ML).\n",
    "- `Facility`: Computing system used.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Project Use:\n",
    "You will use this dataset to:\n",
    "- Analyze **resource usage trends**.\n",
    "- Investigate **which projects use HPC most intensively**.\n",
    "- Compare **job types and facilities**.\n",
    "- Explore **optimization strategies** and implications for scheduling.\n",
    "\n",
    "üìå *Note:* The data has been anonymized and synthesized to protect institutional privacy but reflects real usage patterns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf9cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Synthetic data sample\n",
    "data = pd.DataFrame({\n",
    "    'Application': ['GTC', 'XGC', 'TRANSP', 'GTC', 'XGC', 'GENE'],\n",
    "    'Cores': [512, 1024, 768, 2048, 1536, 1024],\n",
    "    'Runtime_hours': [5.2, 3.1, 6.0, 10.5, 7.2, 4.4],\n",
    "    'Power_kW': [130, 210, 180, 400, 320, 150]\n",
    "})\n",
    "data['Energy_kWh'] = data['Runtime_hours'] * data['Power_kW']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66721d",
   "metadata": {},
   "source": [
    "## üìà Energy Consumption per Application\n",
    "\n",
    "Energy usage is a critical factor in HPC operations ‚Äî especially when considering the **cost and carbon footprint** of running large-scale fusion simulations.\n",
    "\n",
    "In this section, we will explore:\n",
    "- How different fusion applications consume energy,\n",
    "- The computational cost per job type,\n",
    "- Potential opportunities for **energy-efficient computing**.\n",
    "\n",
    "---\n",
    "\n",
    "### üî¨ Simulated Applications\n",
    "Here are some fusion-related workloads you might see:\n",
    "- `PlasmaSim`: Models plasma turbulence and instabilities.\n",
    "- `FusionAI`: Trains ML models on reactor sensor data.\n",
    "- `ReactMat`: Simulates material degradation under neutron flux.\n",
    "- `BeamOpt`: Optimizes beam configurations for inertial confinement.\n",
    "- `DataPost`: Post-processing of experiment output.\n",
    "\n",
    "Each application has an associated **energy footprint**, estimated using:\n",
    "```\n",
    "Energy (kWh) = RuntimeMinutes √ó PowerPerNode √ó NodesRequested √∑ 60\n",
    "```\n",
    "\n",
    "We‚Äôll use simulated `PowerPerNode` values (in kW) to compute energy for each job and **visualize usage per application**.\n",
    "\n",
    "üìä *Your Task:* Group jobs by application and compute total and average energy consumption. Then, identify the **most and least energy-efficient apps**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873db7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Application', y='Energy_kWh', data=data)\n",
    "plt.title('Energy Usage by Fusion Application')\n",
    "plt.ylabel('Total Energy (kWh)')\n",
    "plt.xlabel('Application')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2363ddd4",
   "metadata": {},
   "source": [
    "## üß† Questions for Reflection\n",
    "\n",
    "As you analyze the fusion HPC workloads, use these questions to guide your thinking and shape your findings:\n",
    "\n",
    "### üîé Scientific Insight\n",
    "- What types of fusion workloads dominate HPC usage?\n",
    "- Which experiments appear to be the most resource-intensive?\n",
    "\n",
    "### ‚ö° Energy Awareness\n",
    "- Which applications consume the most energy per job?\n",
    "- Are there apps that could benefit from GPU acceleration or code optimization?\n",
    "\n",
    "### üí° Efficiency Strategies\n",
    "- If you were designing a job scheduler, how would you prioritize jobs?\n",
    "- What trade-offs might exist between runtime, energy, and scientific output?\n",
    "\n",
    "### üå± Sustainability Lens\n",
    "- How can HPC centers reduce energy usage without compromising science?\n",
    "- What role might **renewable energy** and **green computing** play in DOE labs of the future?\n",
    "\n",
    "Use these questions to prepare your **final group reflections** or reports at the end of Day 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60ad034",
   "metadata": {},
   "source": [
    "## üîç Efficiency Metrics\n",
    "\n",
    "Understanding how well compute resources are used is central to optimizing both **cost** and **scientific throughput**.\n",
    "\n",
    "We‚Äôll define and calculate several key metrics:\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Runtime Efficiency\n",
    "Measures how effectively the allocated nodes are used:\n",
    "```\n",
    "RuntimeEfficiency = (EndTime - StartTime) / (AllocatedTime)\n",
    "```\n",
    "High efficiency means minimal idle time.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö° Energy Efficiency (kWh per core-hour)\n",
    "```\n",
    "EnergyPerCoreHour = EnergyConsumed / (RuntimeMinutes √ó CoresPerNode / 60)\n",
    "```\n",
    "Lower values indicate better utilization of compute energy.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† ML Efficiency (optional)\n",
    "If your dataset includes `FusionAI` jobs, you may compare:\n",
    "- **Accuracy per Watt**\n",
    "- **Training Time per kWh**\n",
    "\n",
    "---\n",
    "\n",
    "üìå *Action:* Compute these metrics across job types and identify which workloads show:\n",
    "- The **best resource utilization**, and\n",
    "- The **highest energy efficiency**.\n",
    "\n",
    "Use this to make **data-driven recommendations** to a fictional HPC director on Day 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f1ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Core_Hours'] = data['Cores'] * data['Runtime_hours']\n",
    "data['kWh_per_CoreHour'] = data['Energy_kWh'] / data['Core_Hours']\n",
    "data[['Application', 'Core_Hours', 'kWh_per_CoreHour']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e2edc",
   "metadata": {},
   "source": [
    "## üìâ Visualization: Energy per Core-Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ffbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Application', y='kWh_per_CoreHour', data=data)\n",
    "plt.title('Energy per Core-Hour by Application')\n",
    "plt.ylabel('kWh / Core-Hour')\n",
    "plt.xlabel('Application')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c6c8c",
   "metadata": {},
   "source": [
    "## üìå Takeaways and Implications\n",
    "- Some applications scale more efficiently than others.\n",
    "- High energy cost per core-hour may indicate poor scaling or I/O bottlenecks.\n",
    "- These insights help optimize batch submission strategies and resource allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11148b3",
   "metadata": {},
   "source": [
    "## üß™ Challenge Exercise\n",
    "Use this data to:\n",
    "1. Identify the most efficient application by core-hour.\n",
    "2. Suggest how runtime or core count could be adjusted for better energy efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba678cc",
   "metadata": {},
   "source": [
    "## üìö Further Resources\n",
    "- [NERSC Fusion Workloads](https://www.nersc.gov/science/fusion-energy/)\n",
    "- [Energy-Aware Scheduling Survey (Kocot et al., 2023)](https://www.mdpi.com/1996-1073/16/2/890)\n",
    "- [Top500 and Green500 Rankings](https://www.top500.org/lists/green500/2023/06/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c8bc03",
   "metadata": {},
   "source": [
    "\n",
    "## üß™ Interactive Exercise: DOE Project Scenario Analyzer\n",
    "\n",
    "As part of your capstone, choose a fusion project and analyze its synthetic workload profile.\n",
    "\n",
    "Here‚Äôs an example: Use the filter below to focus on jobs from the **DIII-D** project and generate basic statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377edbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choose a project to simulate (e.g., DIII-D)\n",
    "project_filter = 'DIII-D'\n",
    "project_data = df[df['Project'] == project_filter]\n",
    "\n",
    "# Summary stats\n",
    "print(f\"Summary for project: {project_filter}\")\n",
    "display(project_data.describe(include='all'))\n",
    "\n",
    "# Plot job types\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(data=project_data, x='JobType')\n",
    "plt.title(f\"Job Types for {project_filter}\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a918cf",
   "metadata": {},
   "source": [
    "\n",
    "## üë• Group Project: Insights and Optimization for Fusion Workloads\n",
    "\n",
    "A\n",
    "## üë• Collaborative Group Project: Performance & Energy Strategy for Fusion Science at NERSC\n",
    "\n",
    "### Project Brief\n",
    "\n",
    "You are part of a research computing team tasked with analyzing and improving the efficiency of fusion energy simulations at NERSC. Based on workload analysis data, your team will produce actionable insights that improve how HPC systems are used in fusion science, balancing performance and sustainability.\n",
    "\n",
    "### Project Goals\n",
    "\n",
    "Your team will:\n",
    "\n",
    "1. **Analyze Fusion HPC Workloads**:\n",
    "   - Examine metrics such as CPU hours, GPU utilization, job scaling, memory usage, and I/O performance.\n",
    "   - Identify inefficiencies, bottlenecks, or underutilized resources.\n",
    "\n",
    "2. **Model Energy Usage and Carbon Impact**:\n",
    "   - Estimate energy consumption and emissions using job characteristics and sustainability calculators.\n",
    "   - Compare resource needs across different workloads or user groups.\n",
    "\n",
    "3. **Recommend Performance Optimizations**:\n",
    "   - Suggest ways to improve job throughput, scaling efficiency, or data handling.\n",
    "   - Explore tools like job profiling, containerization, or using newer architectures.\n",
    "\n",
    "4. **Design a Sustainability Strategy**:\n",
    "   - Draft a policy or workflow recommendation that supports energy-efficient computing in fusion science.\n",
    "   - Include tradeoffs between precision, performance, and energy use.\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "- A 5‚Äì7 slide group presentation that includes:\n",
    "  - Your analysis findings and visualizations\n",
    "  - A proposed optimization strategy\n",
    "  - Reflections on the balance between scientific needs and sustainability\n",
    "- Code snippets, charts, or pseudocode demonstrating your data handling and analysis\n",
    "- Optionally: a written 1-page summary or infographic\n",
    "\n",
    "Use Python tools like `pandas`, `matplotlib`, `plotly`, `numpy`, or `dask`. External libraries like `carbonai`, `pyJoules`, or `line_profiler` are also encouraged if relevant.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
